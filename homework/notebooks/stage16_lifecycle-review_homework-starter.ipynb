{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 16 Homework Starter\n",
    "\n",
    "This notebook is a starting point for polishing your final repo and lifecycle mapping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checklist Template\n",
    " - Add checklist elements, as in the examples below, to make sure you cover everything you would like to accomplish\n",
    "- Update this checklist as you finalize your repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-27T21:53:47.260595Z",
     "start_time": "2025-08-27T21:53:47.258281Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stage 16 â€” Repo checklist helpers (auto-check + render)\n",
    "import os, re, json, subprocess\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "ROOT = Path(\".\").resolve()\n",
    "\n",
    "def file_exists(*relpath) -> bool:\n",
    "    return (ROOT.joinpath(*relpath)).exists()\n",
    "\n",
    "def has_readme() -> bool:\n",
    "    return any(p.name.lower()==\"readme.md\" for p in ROOT.iterdir())\n",
    "\n",
    "def has_lifecycle_map() -> bool:\n",
    "    # accept lifecycle_map.md or docs/lifecycle_map.md\n",
    "    for p in [ROOT, ROOT/\"docs\", ROOT/\"handoff\"]:\n",
    "        f = p/\"lifecycle_map.md\"\n",
    "        if f.exists():\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def has_summary_doc() -> bool:\n",
    "    for name in [\"summary.md\", \"stakeholder_summary.md\", \"reflection.md\"]:\n",
    "        for p in [ROOT, ROOT/\"handoff\", ROOT/\"reports\", ROOT/\"docs\"]:\n",
    "            if (p/name).exists():\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def has_framework_table() -> bool:\n",
    "    # look for a markdown with a header row that includes Data/Model/System/Business\n",
    "    candidates = list(ROOT.rglob(\"*.md\"))\n",
    "    for c in candidates:\n",
    "        try:\n",
    "            txt = c.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        if re.search(r\"\\|?\\s*Data\\s*\\|\\s*Model\\s*\\|\\s*System\\s*\\|\\s*Business\\s*\\|\", txt, flags=re.I):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def repo_is_clean() -> bool:\n",
    "    # simple heuristics:\n",
    "    # 1) .gitignore exists\n",
    "    # 2) no large files (>50MB) outside data/ or reports/\n",
    "    # 3) no obvious secrets in env files committed\n",
    "    ok = file_exists(\".gitignore\")\n",
    "    large = []\n",
    "    for p in ROOT.rglob(\"*\"):\n",
    "        if not p.is_file(): \n",
    "            continue\n",
    "        # skip typical dirs\n",
    "        if any(str(p).startswith(str(ROOT/d)) for d in [\"data\", \"reports\", \".git\", \".ipynb_checkpoints\"]):\n",
    "            continue\n",
    "        try:\n",
    "            if p.stat().st_size > 50*1024*1024:\n",
    "                large.append(str(p))\n",
    "        except Exception:\n",
    "            pass\n",
    "    no_large = (len(large) == 0)\n",
    "    # quick secret scan\n",
    "    secret_hits = []\n",
    "    for p in ROOT.rglob(\"*\"):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "        if p.suffix.lower() in {\".png\",\".jpg\",\".jpeg\",\".gif\",\".pdf\",\".zip\",\".gz\",\".pkl\",\".joblib\"}:\n",
    "            continue\n",
    "        try:\n",
    "            txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        if re.search(r\"(api[_-]?key|secret|aws_access_key_id|aws_secret_access_key)=\", txt, flags=re.I):\n",
    "            secret_hits.append(str(p))\n",
    "            break\n",
    "    no_secrets = (len(secret_hits) == 0)\n",
    "    return ok and no_large and no_secrets\n",
    "\n",
    "def repo_complete() -> bool:\n",
    "    # minimal: notebooks/, src/, model/ or app.py, requirements.txt, README.md\n",
    "    must = [\n",
    "        has_readme(),\n",
    "        file_exists(\"requirements.txt\"),\n",
    "    ]\n",
    "    has_any_model_artifacts = file_exists(\"model\") or file_exists(\"app.py\") or file_exists(\"dashboard.py\")\n",
    "    has_src_or_nb = file_exists(\"src\") or file_exists(\"notebooks\")\n",
    "    must.extend([has_any_model_artifacts, has_src_or_nb])\n",
    "    return all(must)\n",
    "\n",
    "checklist = {\n",
    "    \"repo_clean\": ROOT}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Prompts\n",
    "- What stage of the lifecycle was hardest for you, and why?\n",
    "- Which part of your repo is most reusable in a future project?\n",
    "- If a teammate had to pick up your repo tomorrow, what would help them most?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Reflection\n",
    "\n",
    "**1) Which stage of the lifecycle was hardest for me, and why?**  \n",
    "The hardest stage was **deployment and monitoring**. Training the model and cleaning data were straightforward, but exposing the model as a reliable service required careful design of error handling, validation, and monitoring. It was challenging to make the API both robust and easy for others to consume, while also planning for long-term risks like data drift and model decay.\n",
    "\n",
    "**2) Which part of my repo is most reusable in a future project?**  \n",
    "The most reusable part is the **core utilities in `src/`**: the data I/O helpers, preprocessing functions, and the `save_model/load_model` persistence pattern. In addition, the Flask API template (`/predict`, `/meta`, `/plot`) is generic enough to be adapted quickly to other models by only changing the feature names and evaluation metrics. These components can save significant setup time for future projects.\n",
    "\n",
    "**3) If a teammate had to pick up my repo tomorrow, what would help them most?**  \n",
    "Clear documentation is the most helpful asset. The `README.md` explains setup and usage, while `docs/lifecycle_map.md` shows the full pipeline from ingest to monitoring. The `docs/framework_guide_table.md` outlines what to monitor and who owns each step. Together with sample requests and screenshots in `reports/`, a new teammate can understand how to run, test, and extend the project without guesswork. This reduces handoff friction and ensures continuity.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-08-27T21:53:47.977948Z",
     "start_time": "2025-08-27T21:53:47.972404Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
